{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e30f2c3-674b-4e19-8f3c-5216b46819a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image \n",
    "from numpy import load, savez\n",
    "import torch\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import normalize\n",
    "import sys\n",
    "import os\n",
    "#sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1525c3-ef8f-4857-93c6-2ffd7adcc2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d18b0a61-17a6-41dd-a172-3abd02da8b79",
   "metadata": {},
   "source": [
    "# Nuevo intento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ff9269-bcf9-48e7-8f0d-86e54ed18959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def load_latent_vector(name):\n",
    "    \"\"\"Carga el vector latente desde un archivo .npz basado en el nombre de la imagen.\"\"\"\n",
    "    path = f'/mnt/discoAmpliado/viky/images/results_BU_3DFE/{name}/projected_w.npz'\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"El archivo {path} no existe.\")\n",
    "    data = np.load(path)\n",
    "    return data['w']  # Suponiendo que la clave dentro del .npz es 'w'\n",
    "\n",
    "def normalize_vectors(vectors):\n",
    "    \"\"\"Normaliza una lista de vectores usando norma L2.\"\"\"\n",
    "    original_shape = vectors.shape  # Guardamos la forma original\n",
    "    vectors = vectors.reshape(vectors.shape[0], -1)  # Aplanamos a (N, D)\n",
    "    vectors = normalize(vectors, axis=1)  # Normalizamos en la dimensión correcta\n",
    "    return vectors.reshape(original_shape)  # Restauramos la forma original\n",
    "\n",
    "def method_1_average_then_regression(df):\n",
    "    \"\"\"Método 1: Promedia los vectores por emoción y aplica regresión.\"\"\"\n",
    "    results = {}\n",
    "    emotions = ['DI', 'HA', 'SU', 'AN', 'SA', 'FE']  # Suponiendo estas emociones\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        subset = df[df['exp'] == emotion]\n",
    "        vectors = np.array([load_latent_vector(name) for name in subset['name']])\n",
    "        vectors = normalize_vectors(vectors)\n",
    "        avg_vector = np.mean(vectors, axis=0)\n",
    "        \n",
    "        X = np.arange(len(vectors)).reshape(-1, 1)\n",
    "        y = vectors.reshape(vectors.shape[0], -1)  # Aplanamos los vectores antes de la regresión\n",
    "\n",
    "        model = LinearRegression().fit(X, y)\n",
    "        results[emotion] = model.coef_.reshape(1, 18, 512)  # Restauramos la forma original\n",
    "    \n",
    "    return results\n",
    "\n",
    "def method_2_regression_by_emotion_and_level(df):\n",
    "    \"\"\"Método 2: Aplica regresión a cada emoción y nivel de intensidad.\"\"\"\n",
    "    results = {}\n",
    "    emotions = ['DI', 'HA', 'SU', 'AN', 'SA', 'FE']\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        results[emotion] = {}  # Ahora almacenamos los resultados por nivel\n",
    "        \n",
    "        for level in sorted(df['exp_level'].unique()):\n",
    "            subset = df[(df['exp'] == emotion) & (df['exp_level'] == level)]\n",
    "            if subset.empty:\n",
    "                continue\n",
    "            vectors = np.array([load_latent_vector(name) for name in subset['name']])\n",
    "            vectors = normalize_vectors(vectors)\n",
    "            \n",
    "            X = np.arange(len(vectors)).reshape(-1, 1)\n",
    "            y = vectors.reshape(vectors.shape[0], -1)  # Aplanamos los vectores antes de la regresión\n",
    "            \n",
    "            model = LinearRegression().fit(X, y)\n",
    "            results[emotion][level] = model.coef_.reshape(1, 18, 512)  # Guardamos cada nivel separadamente\n",
    "    \n",
    "    return results\n",
    "\n",
    "def method_3_regression_with_level_variable(df):\n",
    "    \"\"\"Método 3: Incluye el nivel como variable numérica en la regresión.\"\"\"\n",
    "    results = {}\n",
    "    emotions = ['DI', 'HA', 'SU', 'AN', 'SA', 'FE']\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        subset = df[df['exp'] == emotion]\n",
    "        vectors = np.array([load_latent_vector(name) for name in subset['name']])\n",
    "        vectors = normalize_vectors(vectors)\n",
    "        levels = subset['exp_level'].values.reshape(-1, 1)\n",
    "\n",
    "        y = vectors.reshape(vectors.shape[0], -1)\n",
    "        \n",
    "        model = LinearRegression().fit(levels, y)\n",
    "        results[emotion] = model.coef_.reshape(1, 18, 512)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_results_as_csv(results, filename):\n",
    "    flat_results = {}\n",
    "    \n",
    "    for key, value in results.items():\n",
    "        flat_results[key] = value.flatten()  # Aplanar la matriz\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(flat_results, orient='index')\n",
    "    df.to_csv(filename)\n",
    "\n",
    "    save_results_as_csv(method_1_results, 'method_1_results.csv')\n",
    "\n",
    "\n",
    "def save_results_as_npz(results, filename):\n",
    "    \"\"\"Guarda los resultados en un archivo NPZ.\"\"\"\n",
    "    np.savez(filename, **results)\n",
    "\n",
    "# Cargar datos y ejecutar procesos\n",
    "df = pd.read_csv('/mnt/discoAmpliado/viky/dataframes/processed_dataframe_combined_fallback.csv')  # Ajustar la ruta al dataset\n",
    "\n",
    "df['idUnique'] = df['id'].astype(str) + df['gender']\n",
    "ids_malos = [\"39M\", \"17M\", \"22M\", \"14M\", \"2F\"]\n",
    "df = df[~df['idUnique'].isin(ids_malos)]\n",
    "\n",
    "method_1_results = method_1_average_then_regression(df)\n",
    "method_2_results = method_2_regression_by_emotion_and_level(df)\n",
    "method_3_results = method_3_regression_with_level_variable(df)\n",
    "\n",
    "print(\"Imprimo shape para controlar formato:\")\n",
    "print(\"Resultados método 1, 'DI': \" + str(method_1_results['DI'].shape))\n",
    "print(\"Resultados método 2, 'DI': \" + str(method_2_results['DI'][1].shape))\n",
    "print(\"Resultados método 3, 'DI': \" + str(method_3_results['DI'].shape))\n",
    "\n",
    "# Guardar resultados\n",
    "##save_results_as_csv(method_1_results, 'method_1_results.csv')\n",
    "save_results_as_npz(method_1_results, 'method_1_results.npz')\n",
    "##save_results_as_csv(method_2_results, 'method_2_results.csv')\n",
    "save_results_as_npz(method_2_results, 'method_2_results.npz')\n",
    "##save_results_as_csv(method_3_results, 'method_3_results.csv')\n",
    "save_results_as_npz(method_3_results, 'method_3_results.npz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b47593-eccd-4642-8ae3-0f2dcff8c9bb",
   "metadata": {},
   "source": [
    "## Printeo la forma de los diccionarios para saber con qué estoy trabajando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e35a8-064f-407b-a835-e39bfe9e37d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shape(diccionario, indent=0):\n",
    "    for clave, valor in diccionario.items():\n",
    "        # Indentación para la estructura\n",
    "        print(\"  \" * indent + f\"Clave: {clave}\", end=' ')\n",
    "        \n",
    "        if isinstance(valor, dict):\n",
    "            # Si el valor es otro diccionario, lo recorremos recursivamente\n",
    "            print(\"; Valor: Diccionario con las siguientes claves: \")\n",
    "            print_shape(valor, indent + 1)\n",
    "        elif isinstance(valor, np.ndarray):\n",
    "            # Si el valor es un array de NumPy, mostramos su forma\n",
    "            print(f\"; Valor: Array de la forma {valor.shape}\")\n",
    "        elif isinstance(valor, list):\n",
    "            # Si el valor es una lista, mostramos su longitud\n",
    "            print(f\"(Lista) - Shape: {len(valor)}\")\n",
    "        else:\n",
    "            # Si no es ni diccionario, ni array ni lista, solo mostramos el tipo\n",
    "            print(f\"({type(valor).__name__})\")\n",
    "\n",
    "print(\"Forma del diccionario correspondiente al método 1: \")\n",
    "print_shape(method_1_results)\n",
    "print(\"Fin del diccionario correspondiente al método 1.\\n\")\n",
    "print(\"Forma del diccionario correspondiente al método 2: \")\n",
    "print_shape(method_2_results)\n",
    "print(\"Fin del diccionario correspondiente al método 2.\\n\")\n",
    "print(\"Forma del diccionario correspondiente al método 3: \")\n",
    "print_shape(method_3_results)\n",
    "print(\"Fin del diccionario correspondiente al método 3.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c567b1-cae2-4726-8d8b-ccd703b6af84",
   "metadata": {},
   "source": [
    "# Intentando analisis de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909b328-f19c-49bf-b4f5-4ef8f7b40dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "\n",
    "# Función para calcular la similitud coseno entre dos vectores\n",
    "def cosine_similarity(v1, v2):\n",
    "    return 1 - cosine(v1.flatten(), v2.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f031f1-c15c-456a-bfe4-9d201f99a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para comparar método 1 vs método 3\n",
    "def compare_results(results1, results3):\n",
    "    similarities = {}\n",
    "    for emotion in results1.keys():\n",
    "        similarities[emotion] = cosine_similarity(results1[emotion], results3[emotion])\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c20f89-9cfb-4c4c-a5c7-42dec34312c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compare_results(method_1_results, method_3_results))\n",
    "print(\"PROBLEMA: me dan resultados re distintos los métodos, cómo sé cuál es mejor?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dccc73-9e70-4e37-bd65-1fa10ff1e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308a57b-12e9-436b-9a0c-478f7a6d1354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stylegan)",
   "language": "python",
   "name": "stylegan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
