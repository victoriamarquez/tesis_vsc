{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e30f2c3-674b-4e19-8f3c-5216b46819a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image \n",
    "from numpy import load, savez\n",
    "import torch\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import normalize\n",
    "import sys\n",
    "import os\n",
    "#sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40dd2f3c-8e29-41ff-a350-6d4b2d7f4d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from numpy import load, savez\n",
    "from IPython.display import Image\n",
    "from IPython import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def optional_print(text, verbosity=True):\n",
    "    if verbosity:\n",
    "        print(text)\n",
    "    else:\n",
    "        ...\n",
    "\n",
    "def getByUniqueIdEmotion(df, idUnique, emotion):\n",
    "    # Todos los registros donde ID est√° EMOCION\n",
    "    gender = idUnique[-1]\n",
    "    id = idUnique[:-1]\n",
    "    res = df.loc[(df['exp'] == emotion) & (df['idUnique'] == idUnique)]\n",
    "    \n",
    "    # Todos los registros donde ID est√° EMOCION, ordenados de menos EMOCION a m√°s EMOCION\n",
    "    res = res.sort_values(by=['exp_level'],ascending=True, inplace=False)\n",
    "    res.reset_index(drop=True, inplace=True)\n",
    "    return res\n",
    "\n",
    "def getNPZ(df, index):\n",
    "    # filename = df['projected_file'][index]\n",
    "    # TODO: volver a load(filename)['w']\n",
    "    fileName = df['name'][index]\n",
    "    filenameFinal = f'/mnt/discoAmpliado/viky/images/results_BU_3DFE/{fileName}/projected_w.npz'\n",
    "    return load(filenameFinal)['w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a69fa1-bdf0-4ed8-bd03-1e18f3ded4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_dir(base_dir, verbosity=True):\n",
    "    if not os.path.exists(base_dir):\n",
    "        optional_print(\"La ruta no existe:\" + base_dir, verbosity)\n",
    "    else:\n",
    "        optional_print(\"Ruta encontrada:\" + base_dir, verbosity)\n",
    "\n",
    "    # Regex pattern to match the filenames\n",
    "    pattern = re.compile(r'^(?P<gender>[MF])(?P<id>\\d{4})_(?P<exp>NE|AN|DI|FE|HA|SA|SU)(?P<exp_level>00|01|02|03|04)(?P<race>WH|BL|IN|AE|AM|LA)_(?P<attribute>F2D)\\.(?P<ext>bmp)$')\n",
    "    # Dictionary to hold the image data\n",
    "    images_data = []\n",
    "\n",
    "    # Walk through the base directory\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            match = pattern.match(file)\n",
    "            if match and match.group('ext') == 'bmp':\n",
    "                image_data = match.groupdict()\n",
    "                image_data['name'] = os.path.splitext(file)[0]\n",
    "                image_data['raw_image_folder'] = root\n",
    "                image_data['file'] = file\n",
    "                image_data['projected_npz'] = \"N\"\n",
    "                image_data['projected_file'] = \"N\"\n",
    "                image_data['idUnique'] = image_data['id'] + image_data['gender']\n",
    "                images_data.append(image_data)\n",
    "    return images_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a669ed9-089d-4fe4-84e1-ca07295dda19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def linearRegression(df, idUnique, emotion, verbose=True):\n",
    "\n",
    "    # 1. Preparar los datos\n",
    "    data = getByUniqueIdEmotion(df, idUnique, emotion)\n",
    "    \n",
    "    # Supongamos que tienes los siguientes datos:\n",
    "    vectores_latentes = [getNPZ(data, index) for index in data.index] # Lista de vectores latentes, cada uno con forma (1, 18, 512)\n",
    "    niveles_emocion = [1, 2, 3, 4]  # Lista de niveles de emocion asociados, cada uno es un escalar\n",
    "    \n",
    "    # Convertir los vectores latentes a una matriz de forma (n_samples, 18 * 512)\n",
    "    X = np.array([vector.reshape(-1) for vector in vectores_latentes])  # Aplana cada vector latente a 1D\n",
    "    y = np.array(niveles_emocion)  # Convertir los niveles de felicidad a un array numpy\n",
    "    \n",
    "    # 2. Ajustar el modelo de regresi√≥n lineal\n",
    "    \n",
    "    # Crear el modelo de regresi√≥n lineal\n",
    "    modelo = LinearRegression()\n",
    "    \n",
    "    # Ajustar el modelo a los datos\n",
    "    modelo.fit(X, y)\n",
    "    \n",
    "    # Obtener la direcci√≥n de emocion en el espacio latente\n",
    "    direccion_emocion = modelo.coef_.reshape(1, 18, 512)\n",
    "\n",
    "    optional_print(f'Executed Linear Regression for person: {idUnique}, emotion: {emotion}.', verbose)\n",
    "    return direccion_emocion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d39c99-6f5d-42ad-96eb-796eff7c3ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "verbosity = True\n",
    "\n",
    "# Define the base directory\n",
    "base_dir = \"/mnt/discoAmpliado/viky/BU_3DFE\"\n",
    "\n",
    "images_data = create_image_dir(base_dir, verbosity)\n",
    "\n",
    "# TODO: Hacer andar el docker que proyecta\n",
    "##align_images(images_data[0:2], verbosity)\n",
    "##df = batch_processing(images_data[0:2], verbosity)\n",
    "# df = load_dataframe()\n",
    "\n",
    "# TODO: A partir de ac√° sigo como si ya tuviera las im√°genes proyectadas, porque sino no llego a ning√∫n lado.\n",
    "df = pd.read_csv(f'/mnt/discoAmpliado/viky/dataframes/processed_dataframe_combined_fallback.csv')\n",
    "df['idUnique'] = df['id'].astype(str) + df['gender']\n",
    "\n",
    "# Crear lista de emociones y eliminar 'NE'\n",
    "emociones = df.exp.unique().tolist()\n",
    "emociones.remove(\"NE\")\n",
    "\n",
    "# Crear lista de IDs y eliminar IDs no deseados\n",
    "ids = df.idUnique.unique().tolist()\n",
    "ids_malos = [\"39M\", \"17M\", \"22M\", \"14M\", \"2F\"] # TODO: Sacar esto cuando pueda arreglar el docker\n",
    "for id_malo in ids_malos:\n",
    "    ids.remove(id_malo)\n",
    "\n",
    "# Crear un DataFrame vac√≠o con IDs como √≠ndice y emociones como columnas\n",
    "emociones_total_LR = pd.DataFrame(index=ids, columns=emociones)\n",
    "emociones_total_PCA = pd.DataFrame(index=ids, columns=emociones)\n",
    "\n",
    "# Calcular el vector de cada emoci√≥n para cada persona\n",
    "for emocion in emociones:\n",
    "    for idUnique in ids:\n",
    "        # LR\n",
    "        direccion_emocion = linearRegression(df, idUnique, emocion, False)\n",
    "        emociones_total_LR.at[idUnique, emocion] = direccion_emocion.flatten()\n",
    "        \n",
    "        # PCA\n",
    "        ##direccion_emocion = executePCA(df, idUnique, emocion, False)\n",
    "        ##emociones_total_PCA.at[idUnique, emocion] = direccion_emocion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc4499-228b-411e-adb5-31f6a37de913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc()[0]\n",
    "getNPZ(df, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8b02c-9231-4722-96aa-77532df3ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def restar_neutro(df, vectores):\n",
    "    \"\"\"\n",
    "    Resta el vector de expresi√≥n neutra a cada imagen de la misma persona.\n",
    "\n",
    "    Par√°metros:\n",
    "    - df: DataFrame con informaci√≥n de las im√°genes.\n",
    "    - vectores: Diccionario con los vectores de cada imagen. {nombre_imagen: vector}\n",
    "    \n",
    "    Retorna:\n",
    "    - nuevo_diccionario: {nombre_imagen: vector_transformado}\n",
    "    \"\"\"\n",
    "    nuevo_diccionario = {}\n",
    "    \n",
    "    for idUnique in df['idUnique'].unique():\n",
    "        # Obtener el vector neutro de la persona\n",
    "        fila_neutra = df[(df['idUnique'] == idUnique) & (df['exp'] == 'NE')]  # NE ser√≠a neutral\n",
    "        if fila_neutra.empty:\n",
    "            continue\n",
    "        vector_neutro = vectores[fila_neutra.iloc[0]['name']]\n",
    "\n",
    "        # Restarlo a las otras expresiones\n",
    "        for _, fila in df[df['idUnique'] == idUnique].iterrows():\n",
    "            nombre_imagen = fila['name']\n",
    "            if nombre_imagen in vectores:\n",
    "                nuevo_diccionario[nombre_imagen] = vectores[nombre_imagen] - vector_neutro\n",
    "\n",
    "    return nuevo_diccionario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae95b8-74a4-4c4f-8a36-03141075190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def obtener_vectores_promediados(df, vectores_neutralizados):\n",
    "    \"\"\"\n",
    "    Promedia los 4 niveles de cada emoci√≥n para cada persona.\n",
    "\n",
    "    Par√°metros:\n",
    "    - df: DataFrame con informaci√≥n de las im√°genes.\n",
    "    - vectores_neutralizados: Diccionario con los vectores restados.\n",
    "\n",
    "    Retorna:\n",
    "    - diccionario_promediado: {idUnique: {emocion: vector_promediado}}\n",
    "    \"\"\"\n",
    "    diccionario_promediado = {}\n",
    "\n",
    "    for idUnique in df['idUnique'].unique():\n",
    "        diccionario_promediado[idUnique] = {}\n",
    "\n",
    "        for emocion in df['exp'].unique():\n",
    "            if emocion == 'NE':  # No considerar la expresi√≥n neutra\n",
    "                continue\n",
    "\n",
    "            # Obtener los vectores de los 4 niveles\n",
    "            filas = df[(df['idUnique'] == idUnique) & (df['exp'] == emocion)]\n",
    "            vectores = [vectores_neutralizados[fila['name']] for _, fila in filas.iterrows()]\n",
    "\n",
    "            # Normalizar cada vector y luego promediar\n",
    "            if vectores:\n",
    "                vectores = np.array(vectores)\n",
    "                vectores_normalizados = normalize(vectores, axis=1)  # Normaliza cada vector individualmente\n",
    "                vector_promedio = np.mean(vectores_normalizados, axis=0)\n",
    "\n",
    "                diccionario_promediado[idUnique][emocion] = vector_promedio\n",
    "\n",
    "    return diccionario_promediado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8090531f-2451-4837-ade2-cacf32d91b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def calcular_direccion_emocion(df, vectores_promediados):\n",
    "    \"\"\"\n",
    "    Usa regresi√≥n lineal para encontrar la direcci√≥n de cada emoci√≥n.\n",
    "\n",
    "    Par√°metros:\n",
    "    - df: DataFrame con informaci√≥n de las im√°genes.\n",
    "    - vectores_promediados: {idUnique: {emocion: vector}}\n",
    "\n",
    "    Retorna:\n",
    "    - direcciones: {emocion: vector_direccion}\n",
    "    \"\"\"\n",
    "    direcciones = {}\n",
    "\n",
    "    for emocion in df['exp'].unique():\n",
    "        if emocion == 'NE':\n",
    "            continue\n",
    "\n",
    "        X = []\n",
    "        for idUnique in vectores_promediados:\n",
    "            if emocion in vectores_promediados[idUnique]:\n",
    "                X.append(vectores_promediados[idUnique][emocion].flatten())  # Asegurarse de que sean arrays 1D\n",
    "\n",
    "        if X:\n",
    "            X = np.array(X)\n",
    "            y = np.ones(len(X))  # No importa realmente el valor de y, porque nos interesa la direcci√≥n\n",
    "\n",
    "            modelo = LinearRegression(fit_intercept=False)\n",
    "            modelo.fit(X, y)\n",
    "\n",
    "            direcciones[emocion] = modelo.coef_\n",
    "\n",
    "    return direcciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7180c651-6f5e-452a-aeb3-a2e53f76c4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1525c3-ef8f-4857-93c6-2ffd7adcc2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e00cd9-6271-40f4-8537-66939133a181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ff9269-bcf9-48e7-8f0d-86e54ed18959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados m√©todo 1, 'DI': (1, 18, 512)\n",
      "Resultados m√©todo 2, 'DI': (1, 18, 512)\n",
      "Resultados m√©todo 3, 'DI': (1, 18, 512)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def load_latent_vector(name):\n",
    "    \"\"\"Carga el vector latente desde un archivo .npz basado en el nombre de la imagen.\"\"\"\n",
    "    path = f'/mnt/discoAmpliado/viky/images/results_BU_3DFE/{name}/projected_w.npz'\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"El archivo {path} no existe.\")\n",
    "    data = np.load(path)\n",
    "    return data['w']  # Suponiendo que la clave dentro del .npz es 'w'\n",
    "\n",
    "def normalize_vectors(vectors):\n",
    "    \"\"\"Normaliza una lista de vectores usando norma L2.\"\"\"\n",
    "    original_shape = vectors.shape  # Guardamos la forma original\n",
    "    vectors = vectors.reshape(vectors.shape[0], -1)  # Aplanamos a (N, D)\n",
    "    vectors = normalize(vectors, axis=1)  # Normalizamos en la dimensi√≥n correcta\n",
    "    return vectors.reshape(original_shape)  # Restauramos la forma original\n",
    "\n",
    "def method_1_average_then_regression(df):\n",
    "    \"\"\"M√©todo 1: Promedia los vectores por emoci√≥n y aplica regresi√≥n.\"\"\"\n",
    "    results = {}\n",
    "    emotions = ['DI', 'HA', 'SU', 'AN', 'SA', 'FE']  # Suponiendo estas emociones\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        subset = df[df['exp'] == emotion]\n",
    "        vectors = np.array([load_latent_vector(name) for name in subset['name']])\n",
    "        vectors = normalize_vectors(vectors)\n",
    "        avg_vector = np.mean(vectors, axis=0)\n",
    "        \n",
    "        X = np.arange(len(vectors)).reshape(-1, 1)\n",
    "        y = vectors.reshape(vectors.shape[0], -1)  # Aplanamos los vectores antes de la regresi√≥n\n",
    "\n",
    "        model = LinearRegression().fit(X, y)\n",
    "        results[emotion] = model.coef_.reshape(1, 18, 512)  # Restauramos la forma original\n",
    "    \n",
    "    return results\n",
    "\n",
    "def method_2_regression_by_emotion_and_level(df):\n",
    "    \"\"\"M√©todo 2: Aplica regresi√≥n a cada emoci√≥n y nivel de intensidad.\"\"\"\n",
    "    results = {}\n",
    "    emotions = ['DI', 'HA', 'SU', 'AN', 'SA', 'FE']\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        results[emotion] = {}  # Ahora almacenamos los resultados por nivel\n",
    "        \n",
    "        for level in sorted(df['exp_level'].unique()):\n",
    "            subset = df[(df['exp'] == emotion) & (df['exp_level'] == level)]\n",
    "            if subset.empty:\n",
    "                continue\n",
    "            vectors = np.array([load_latent_vector(name) for name in subset['name']])\n",
    "            vectors = normalize_vectors(vectors)\n",
    "            \n",
    "            X = np.arange(len(vectors)).reshape(-1, 1)\n",
    "            y = vectors.reshape(vectors.shape[0], -1)  # Aplanamos los vectores antes de la regresi√≥n\n",
    "            \n",
    "            model = LinearRegression().fit(X, y)\n",
    "            results[emotion][level] = model.coef_.reshape(1, 18, 512)  # Guardamos cada nivel separadamente\n",
    "    \n",
    "    return results\n",
    "\n",
    "def method_3_regression_with_level_variable(df):\n",
    "    \"\"\"M√©todo 3: Incluye el nivel como variable num√©rica en la regresi√≥n.\"\"\"\n",
    "    results = {}\n",
    "    emotions = ['DI', 'HA', 'SU', 'AN', 'SA', 'FE']\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        subset = df[df['exp'] == emotion]\n",
    "        vectors = np.array([load_latent_vector(name) for name in subset['name']])\n",
    "        vectors = normalize_vectors(vectors)\n",
    "        levels = subset['exp_level'].values.reshape(-1, 1)\n",
    "\n",
    "        y = vectors.reshape(vectors.shape[0], -1)\n",
    "        \n",
    "        model = LinearRegression().fit(levels, y)\n",
    "        results[emotion] = model.coef_.reshape(1, 18, 512)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_results_as_csv(results, filename):\n",
    "    flat_results = {}\n",
    "    \n",
    "    for key, value in results.items():\n",
    "        flat_results[key] = value.flatten()  # Aplanar la matriz\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(flat_results, orient='index')\n",
    "    df.to_csv(filename)\n",
    "\n",
    "    save_results_as_csv(method_1_results, 'method_1_results.csv')\n",
    "\n",
    "\n",
    "def save_results_as_npz(results, filename):\n",
    "    \"\"\"Guarda los resultados en un archivo NPZ.\"\"\"\n",
    "    np.savez(filename, **results)\n",
    "\n",
    "# Cargar datos y ejecutar procesos\n",
    "df = pd.read_csv('/mnt/discoAmpliado/viky/dataframes/processed_dataframe_combined_fallback.csv')  # Ajustar la ruta al dataset\n",
    "df['idUnique'] = df['id'].astype(str) + df['gender']\n",
    "ids_malos = [\"39M\", \"17M\", \"22M\", \"14M\", \"2F\"]\n",
    "df = df[~df['idUnique'].isin(ids_malos)]\n",
    "\n",
    "method_1_results = method_1_average_then_regression(df)\n",
    "method_2_results = method_2_regression_by_emotion_and_level(df)\n",
    "method_3_results = method_3_regression_with_level_variable(df)\n",
    "\n",
    "print(\"Resultados m√©todo 1, 'DI': \" + str(method_1_results['DI'].shape))\n",
    "print(\"Resultados m√©todo 2, 'DI': \" + str(method_2_results['DI'][1].shape))\n",
    "print(\"Resultados m√©todo 3, 'DI': \" + str(method_3_results['DI'].shape))\n",
    "\n",
    "# Guardar resultados\n",
    "##save_results_as_csv(method_1_results, 'method_1_results.csv')\n",
    "save_results_as_npz(method_1_results, 'method_1_results.npz')\n",
    "##save_results_as_csv(method_2_results, 'method_2_results.csv')\n",
    "save_results_as_npz(method_2_results, 'method_2_results.npz')\n",
    "##save_results_as_csv(method_3_results, 'method_3_results.csv')\n",
    "save_results_as_npz(method_3_results, 'method_3_results.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c2e35a8-064f-407b-a835-e39bfe9e37d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del diccionario correspondiente al m√©todo 1: \n",
      "Clave: DI ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: HA ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: SU ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: AN ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: SA ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: FE ; Valor: Array de la forma (1, 18, 512)\n",
      "Fin del diccionario correspondiente al m√©todo 1.\n",
      "\n",
      "Forma del diccionario correspondiente al m√©todo 2: \n",
      "Clave: DI ; Valor: Diccionario con las siguientes claves: \n",
      "  Clave: 1 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 2 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 3 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 4 ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: HA ; Valor: Diccionario con las siguientes claves: \n",
      "  Clave: 1 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 2 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 3 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 4 ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: SU ; Valor: Diccionario con las siguientes claves: \n",
      "  Clave: 1 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 2 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 3 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 4 ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: AN ; Valor: Diccionario con las siguientes claves: \n",
      "  Clave: 1 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 2 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 3 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 4 ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: SA ; Valor: Diccionario con las siguientes claves: \n",
      "  Clave: 1 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 2 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 3 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 4 ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: FE ; Valor: Diccionario con las siguientes claves: \n",
      "  Clave: 1 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 2 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 3 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 4 ; Valor: Array de la forma (1, 18, 512)\n",
      "Fin del diccionario correspondiente al m√©todo 2.\n",
      "\n",
      "Forma del diccionario correspondiente al m√©todo 3: \n",
      "Clave: DI ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: HA ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: SU ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: AN ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: SA ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: FE ; Valor: Array de la forma (1, 18, 512)\n",
      "Fin del diccionario correspondiente al m√©todo 3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_shape(diccionario, indent=0):\n",
    "    for clave, valor in diccionario.items():\n",
    "        # Indentaci√≥n para la estructura\n",
    "        print(\"  \" * indent + f\"Clave: {clave}\", end=' ')\n",
    "        \n",
    "        if isinstance(valor, dict):\n",
    "            # Si el valor es otro diccionario, lo recorremos recursivamente\n",
    "            print(\"; Valor: Diccionario con las siguientes claves: \")\n",
    "            print_shape(valor, indent + 1)\n",
    "        elif isinstance(valor, np.ndarray):\n",
    "            # Si el valor es un array de NumPy, mostramos su forma\n",
    "            print(f\"; Valor: Array de la forma {valor.shape}\")\n",
    "        elif isinstance(valor, list):\n",
    "            # Si el valor es una lista, mostramos su longitud\n",
    "            print(f\"(Lista) - Shape: {len(valor)}\")\n",
    "        else:\n",
    "            # Si no es ni diccionario, ni array ni lista, solo mostramos el tipo\n",
    "            print(f\"({type(valor).__name__})\")\n",
    "\n",
    "print(\"Forma del diccionario correspondiente al m√©todo 1: \")\n",
    "print_shape(method_1_results)\n",
    "print(\"Fin del diccionario correspondiente al m√©todo 1.\\n\")\n",
    "print(\"Forma del diccionario correspondiente al m√©todo 2: \")\n",
    "print_shape(method_2_results)\n",
    "print(\"Fin del diccionario correspondiente al m√©todo 2.\\n\")\n",
    "print(\"Forma del diccionario correspondiente al m√©todo 3: \")\n",
    "print_shape(method_3_results)\n",
    "print(\"Fin del diccionario correspondiente al m√©todo 3.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c6da64-2237-4717-8527-6fadfaa1054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cosine\n",
    "import seaborn as sns\n",
    "\n",
    "# Funci√≥n para calcular la similitud coseno entre vectores\n",
    "def cosine_similarity(v1, v2):\n",
    "    return 1 - cosine(v1.flatten(), v2.flatten())\n",
    "\n",
    "# Estrategia 1: Comparaci√≥n de similitud coseno\n",
    "# Explicaci√≥n: Calculamos la similitud coseno entre los vectores de cada emoci√≥n para evaluar si los m√©todos producen resultados similares.\n",
    "def compare_cosine_similarity(results1, results2, results2_avg):\n",
    "    similarities = {}\n",
    "    for emotion in results1.keys():\n",
    "        sim_1_3 = cosine_similarity(results1[emotion], results2_avg[emotion])\n",
    "        sim_2_3 = np.mean([cosine_similarity(results2[emotion][level], results2_avg[emotion]) for level in results2[emotion]])\n",
    "        similarities[emotion] = (sim_1_3, sim_2_3)\n",
    "    return similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c4a0aca-1626-4ffe-870c-070293ceba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrategia 2: Comparaci√≥n de dispersi√≥n\n",
    "# Explicaci√≥n: Medimos la varianza de los valores en cada vector para evaluar el nivel de ruido en cada m√©todo.\n",
    "def compute_variance(results):\n",
    "    variances = {emotion: np.var(vector) for emotion, vector in results.items()}\n",
    "    return variances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65228fd4-8f2d-40a5-9fae-f3347ac0c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrategia 4: Visualizaci√≥n con PCA\n",
    "# Explicaci√≥n: Reducimos la dimensionalidad de los vectores latentes y graficamos para ver c√≥mo se agrupan los m√©todos.\n",
    "def plot_pca(results1, results2_avg, results3):\n",
    "    data = []\n",
    "    labels = []\n",
    "    methods = []\n",
    "    \n",
    "    for emotion in results1.keys():\n",
    "        data.append(results1[emotion].flatten())\n",
    "        labels.append(emotion)\n",
    "        methods.append(\"M√©todo 1\")\n",
    "        \n",
    "        data.append(results2_avg[emotion].flatten())\n",
    "        labels.append(emotion)\n",
    "        methods.append(\"M√©todo 2\")\n",
    "        \n",
    "        data.append(results3[emotion].flatten())\n",
    "        labels.append(emotion)\n",
    "        methods.append(\"M√©todo 3\")\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    transformed = pca.fit_transform(data)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=transformed[:, 0], y=transformed[:, 1], hue=labels, style=methods, s=100)\n",
    "    plt.title(\"Visualizaci√≥n PCA de vectores latentes por m√©todo\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08478e88-c709-4d88-82b4-26df88bf6ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrategia 5: Test de estabilidad con Bootstrapping\n",
    "# Explicaci√≥n: Muestreamos aleatoriamente subconjuntos de datos y evaluamos la varianza de los resultados para ver qu√© m√©todo es m√°s estable.\n",
    "def bootstrap_stability(results, num_samples=100):\n",
    "    stability = {}\n",
    "    for emotion in results.keys():\n",
    "        boot_samples = []\n",
    "        for _ in range(num_samples):\n",
    "            sampled_indices = np.random.choice(results[emotion].shape[1], size=results[emotion].shape[1], replace=True)\n",
    "            sampled_vector = results[emotion][:, sampled_indices, :]\n",
    "            boot_samples.append(sampled_vector.flatten())\n",
    "        \n",
    "        boot_samples = np.array(boot_samples)\n",
    "        stability[emotion] = np.var(boot_samples)\n",
    "    return stability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5557bc96-897f-4ea8-80d8-96794d68b3b1",
   "metadata": {},
   "source": [
    "### Similitud Coseno\n",
    "\n",
    "C√≥mo interpretar los resultados\n",
    "\n",
    "- Un valor cercano a 1 indica que los vectores son casi id√©nticos.\n",
    "- Un valor cercano a 0 indica que son muy diferentes.\n",
    "- Si el m√©todo 2 tiene valores similares a los otros, significa que promediar los niveles no cambia tanto la direcci√≥n final del vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75c149a1-9a89-4d6e-8025-154a7f2234fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (124842550.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_153614/124842550.py\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    CHATGPT DIJO ESTO: üîπ C√≥mo ejecutarlo\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "cosine_results = compare_cosine_similarity(method_1_results, method_2_results, method_3_results)\n",
    "print(cosine_results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CHATGPT DIJO ESTO: üîπ C√≥mo ejecutarlo\n",
    "Llam√°s a la funci√≥n con los resultados de cada m√©todo:\n",
    "\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "cosine_results = compare_cosine_similarity(results_method_1, results_method_2, results_method_2_avg)\n",
    "Esto devuelve un diccionario con la similitud coseno entre:\n",
    "\n",
    "M√©todo 1 y M√©todo 2 Promediado\n",
    "Cada nivel del M√©todo 2 y su versi√≥n promediada\n",
    "üîπ C√≥mo interpretar los resultados\n",
    "Valores cercanos a 1 ‚Üí Los m√©todos producen resultados similares.\n",
    "Valores cercanos a 0 ‚Üí Hay diferencias significativas.\n",
    "Si el M√©todo 2 promediado es muy diferente de sus niveles originales, significa que promediar puede estar perdiendo informaci√≥n importante.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d226b323-a556-450f-b69e-bad204efae5e",
   "metadata": {},
   "source": [
    "### Comparaci√≥n de Dispersi√≥n (Varianza)\n",
    "\n",
    "C√≥mo interpretar los resultados\n",
    "- Si la varianza es alta, significa que los valores dentro del m√©todo son m√°s dispersos ‚Üí el m√©todo es m√°s sensible a variaciones.\n",
    "- Si la varianza es baja, indica que los valores est√°n m√°s agrupados ‚Üí el m√©todo es m√°s estable.\n",
    "- Si el m√©todo 2 tiene mucha m√°s varianza, significa que los diferentes niveles de emoci√≥n generan m√°s ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c95696e-7caf-40f0-88e1-dbe025975b79",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_153614/782573131.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvariance_results_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_1_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvariance_results_2_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_2_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvariance_results_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_3_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_153614/2533375433.py\u001b[0m in \u001b[0;36mcompute_variance\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Explicaci√≥n: Medimos la varianza de los valores en cada vector para evaluar el nivel de ruido en cada m√©todo.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvariances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0memotion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvariances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_153614/2533375433.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Explicaci√≥n: Medimos la varianza de los valores en cada vector para evaluar el nivel de ruido en cada m√©todo.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvariances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0memotion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvariances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvar\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/stylegan/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mvar\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m   3722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3723\u001b[0m     return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0;32m-> 3724\u001b[0;31m                          **kwargs)\n\u001b[0m\u001b[1;32m   3725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/stylegan/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    223\u001b[0m                                  subok=False)\n\u001b[1;32m    224\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0marrmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrmean\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;31m# Compute sum of squared deviations from mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "variance_results_1 = compute_variance(method_1_results)\n",
    "variance_results_2_avg = compute_variance(method_2_results)\n",
    "variance_results_3 = compute_variance(method_3_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a491fb-f57e-4696-8201-db6c3cd094fa",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n con PCA\n",
    "\n",
    "C√≥mo interpretar los resultados\n",
    "- Si los puntos de diferentes m√©todos est√°n cercanos, significa que los m√©todos generan resultados similares.\n",
    "- Si est√°n muy dispersos o en grupos separados, significa que hay diferencias estructurales en los m√©todos.\n",
    "- Si el m√©todo 2 se distribuye en diferentes regiones, significa que los niveles de emoci√≥n generan variaciones notables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4d28db8-1151-40c6-95ff-2e375873368d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_153614/1241211546.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_pca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_1_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_2_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_3_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_153614/3633025410.py\u001b[0m in \u001b[0;36mplot_pca\u001b[0;34m(results1, results2_avg, results3)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmethods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"M√©todo 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults2_avg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmethods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"M√©todo 2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "plot_pca(method_1_results, method_2_results, method_3_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c1be7-9d61-4177-ac23-dd2cf0399c63",
   "metadata": {},
   "source": [
    "### Test de Estabilidad con Bootstrapping\n",
    "\n",
    "C√≥mo interpretar los resultados\n",
    "- Si la estabilidad de un m√©todo es alta, significa que peque√±as variaciones en los datos no alteran mucho el resultado.\n",
    "- Si es baja, el m√©todo es sensible a los cambios en los datos.\n",
    "- Si el m√©todo 2 muestra menos estabilidad, significa que agregar los niveles de emoci√≥n introduce ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf3d5357-e314-4b4b-ae45-07c372137f6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_153614/1989429621.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbootstrap_results_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_stability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_1_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbootstrap_results_2_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_stability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_2_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbootstrap_results_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_stability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_3_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_153614/3507704705.py\u001b[0m in \u001b[0;36mbootstrap_stability\u001b[0;34m(results, num_samples)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mboot_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0msampled_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0msampled_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mboot_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "bootstrap_results_1 = bootstrap_stability(method_1_results)\n",
    "bootstrap_results_2_avg = bootstrap_stability(method_2_results)\n",
    "bootstrap_results_3 = bootstrap_stability(method_3_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87339a1-470b-4c1c-b20f-a0ff03152dbc",
   "metadata": {},
   "source": [
    "|Estrategia\t|Qu√© indica|\tC√≥mo saber si un m√©todo es mejor?|\n",
    "|---|---|---|\n",
    "|Similitud coseno|\tQu√© tan parecidos son los m√©todos|\tValores cercanos a 1 significan similitud alta|\n",
    "|Varianza|\tSi hay ruido en los resultados|\tVarianza baja significa mayor estabilidad|\n",
    "|PCA|\tC√≥mo se agrupan los m√©todos|\tM√©todos agrupados = resultados similares|\n",
    "|Bootstrapping|\tEstabilidad de los m√©todos|\tEstabilidad alta = m√©todo m√°s robusto|\n",
    "\n",
    "üí° Conclusi√≥n:\n",
    "Si el m√©todo 2 tiene menor estabilidad y m√°s varianza, quiz√°s el promedio de los niveles no ayuda tanto.\n",
    "Si los tres m√©todos son similares en la similitud coseno y PCA, entonces cualquiera de ellos podr√≠a ser v√°lido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965cfd87-f5cb-4041-8781-b25f8b08c967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909b328-f19c-49bf-b4f5-4ef8f7b40dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f031f1-c15c-456a-bfe4-9d201f99a599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c20f89-9cfb-4c4c-a5c7-42dec34312c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2dccc73-9e70-4e37-bd65-1fa10ff1e79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>id</th>\n",
       "      <th>exp</th>\n",
       "      <th>exp_level</th>\n",
       "      <th>race</th>\n",
       "      <th>attribute</th>\n",
       "      <th>ext</th>\n",
       "      <th>name</th>\n",
       "      <th>raw_image_folder</th>\n",
       "      <th>file</th>\n",
       "      <th>projected_npz</th>\n",
       "      <th>projected_file</th>\n",
       "      <th>idUnique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>AN</td>\n",
       "      <td>1</td>\n",
       "      <td>WH</td>\n",
       "      <td>F2D</td>\n",
       "      <td>bmp</td>\n",
       "      <td>F0054_AN01WH_F2D</td>\n",
       "      <td>/home/vicky/Documents/BU_3DFE/F0054</td>\n",
       "      <td>F0054_AN01WH_F2D.bmp</td>\n",
       "      <td>[[[ 0.9724985   0.13166972  1.008977   ...  0....</td>\n",
       "      <td>images/results/BU_3DFE/F0054_AN01WH_F2D/projec...</td>\n",
       "      <td>54F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>NE</td>\n",
       "      <td>0</td>\n",
       "      <td>WH</td>\n",
       "      <td>F2D</td>\n",
       "      <td>bmp</td>\n",
       "      <td>F0054_NE00WH_F2D</td>\n",
       "      <td>/home/vicky/Documents/BU_3DFE/F0054</td>\n",
       "      <td>F0054_NE00WH_F2D.bmp</td>\n",
       "      <td>[[[-0.78966004  2.7504096   1.835071   ...  0....</td>\n",
       "      <td>images/results/BU_3DFE/F0054_NE00WH_F2D/projec...</td>\n",
       "      <td>54F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>SU</td>\n",
       "      <td>1</td>\n",
       "      <td>WH</td>\n",
       "      <td>F2D</td>\n",
       "      <td>bmp</td>\n",
       "      <td>F0054_SU01WH_F2D</td>\n",
       "      <td>/home/vicky/Documents/BU_3DFE/F0054</td>\n",
       "      <td>F0054_SU01WH_F2D.bmp</td>\n",
       "      <td>[[[-0.95715564 -0.6468469   0.31578222 ... -0....</td>\n",
       "      <td>images/results/BU_3DFE/F0054_SU01WH_F2D/projec...</td>\n",
       "      <td>54F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>HA</td>\n",
       "      <td>3</td>\n",
       "      <td>WH</td>\n",
       "      <td>F2D</td>\n",
       "      <td>bmp</td>\n",
       "      <td>F0054_HA03WH_F2D</td>\n",
       "      <td>/home/vicky/Documents/BU_3DFE/F0054</td>\n",
       "      <td>F0054_HA03WH_F2D.bmp</td>\n",
       "      <td>[[[ 0.21925983  0.20221505  0.10414152 ...  0....</td>\n",
       "      <td>images/results/BU_3DFE/F0054_HA03WH_F2D/projec...</td>\n",
       "      <td>54F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>FE</td>\n",
       "      <td>4</td>\n",
       "      <td>WH</td>\n",
       "      <td>F2D</td>\n",
       "      <td>bmp</td>\n",
       "      <td>F0054_FE04WH_F2D</td>\n",
       "      <td>/home/vicky/Documents/BU_3DFE/F0054</td>\n",
       "      <td>F0054_FE04WH_F2D.bmp</td>\n",
       "      <td>[[[ 0.08871058 -1.3138419   0.97178036 ...  1....</td>\n",
       "      <td>images/results/BU_3DFE/F0054_FE04WH_F2D/projec...</td>\n",
       "      <td>54F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender  id exp  exp_level race attribute  ext              name  \\\n",
       "124      F  54  AN          1   WH       F2D  bmp  F0054_AN01WH_F2D   \n",
       "125      F  54  NE          0   WH       F2D  bmp  F0054_NE00WH_F2D   \n",
       "126      F  54  SU          1   WH       F2D  bmp  F0054_SU01WH_F2D   \n",
       "127      F  54  HA          3   WH       F2D  bmp  F0054_HA03WH_F2D   \n",
       "128      F  54  FE          4   WH       F2D  bmp  F0054_FE04WH_F2D   \n",
       "\n",
       "                        raw_image_folder                  file  \\\n",
       "124  /home/vicky/Documents/BU_3DFE/F0054  F0054_AN01WH_F2D.bmp   \n",
       "125  /home/vicky/Documents/BU_3DFE/F0054  F0054_NE00WH_F2D.bmp   \n",
       "126  /home/vicky/Documents/BU_3DFE/F0054  F0054_SU01WH_F2D.bmp   \n",
       "127  /home/vicky/Documents/BU_3DFE/F0054  F0054_HA03WH_F2D.bmp   \n",
       "128  /home/vicky/Documents/BU_3DFE/F0054  F0054_FE04WH_F2D.bmp   \n",
       "\n",
       "                                         projected_npz  \\\n",
       "124  [[[ 0.9724985   0.13166972  1.008977   ...  0....   \n",
       "125  [[[-0.78966004  2.7504096   1.835071   ...  0....   \n",
       "126  [[[-0.95715564 -0.6468469   0.31578222 ... -0....   \n",
       "127  [[[ 0.21925983  0.20221505  0.10414152 ...  0....   \n",
       "128  [[[ 0.08871058 -1.3138419   0.97178036 ...  1....   \n",
       "\n",
       "                                        projected_file idUnique  \n",
       "124  images/results/BU_3DFE/F0054_AN01WH_F2D/projec...      54F  \n",
       "125  images/results/BU_3DFE/F0054_NE00WH_F2D/projec...      54F  \n",
       "126  images/results/BU_3DFE/F0054_SU01WH_F2D/projec...      54F  \n",
       "127  images/results/BU_3DFE/F0054_HA03WH_F2D/projec...      54F  \n",
       "128  images/results/BU_3DFE/F0054_FE04WH_F2D/projec...      54F  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308a57b-12e9-436b-9a0c-478f7a6d1354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stylegan)",
   "language": "python",
   "name": "stylegan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
