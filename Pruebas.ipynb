{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e30f2c3-674b-4e19-8f3c-5216b46819a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image \n",
    "from numpy import load, savez\n",
    "import torch\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import normalize\n",
    "import sys\n",
    "import os\n",
    "#sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40dd2f3c-8e29-41ff-a350-6d4b2d7f4d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from numpy import load, savez\n",
    "from IPython.display import Image\n",
    "from IPython import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def optional_print(text, verbosity=True):\n",
    "    if verbosity:\n",
    "        print(text)\n",
    "    else:\n",
    "        ...\n",
    "\n",
    "def getByUniqueIdEmotion(df, idUnique, emotion):\n",
    "    # Todos los registros donde ID está EMOCION\n",
    "    gender = idUnique[-1]\n",
    "    id = idUnique[:-1]\n",
    "    res = df.loc[(df['exp'] == emotion) & (df['idUnique'] == idUnique)]\n",
    "    \n",
    "    # Todos los registros donde ID está EMOCION, ordenados de menos EMOCION a más EMOCION\n",
    "    res = res.sort_values(by=['exp_level'],ascending=True, inplace=False)\n",
    "    res.reset_index(drop=True, inplace=True)\n",
    "    return res\n",
    "\n",
    "def getNPZ(df, index):\n",
    "    # filename = df['projected_file'][index]\n",
    "    # TODO: volver a load(filename)['w']\n",
    "    fileName = df['name'][index]\n",
    "    filenameFinal = f'/mnt/discoAmpliado/viky/images/results_BU_3DFE/{fileName}/projected_w.npz'\n",
    "    return load(filenameFinal)['w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a69fa1-bdf0-4ed8-bd03-1e18f3ded4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_dir(base_dir, verbosity=True):\n",
    "    if not os.path.exists(base_dir):\n",
    "        optional_print(\"La ruta no existe:\" + base_dir, verbosity)\n",
    "    else:\n",
    "        optional_print(\"Ruta encontrada:\" + base_dir, verbosity)\n",
    "\n",
    "    # Regex pattern to match the filenames\n",
    "    pattern = re.compile(r'^(?P<gender>[MF])(?P<id>\\d{4})_(?P<exp>NE|AN|DI|FE|HA|SA|SU)(?P<exp_level>00|01|02|03|04)(?P<race>WH|BL|IN|AE|AM|LA)_(?P<attribute>F2D)\\.(?P<ext>bmp)$')\n",
    "    # Dictionary to hold the image data\n",
    "    images_data = []\n",
    "\n",
    "    # Walk through the base directory\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            match = pattern.match(file)\n",
    "            if match and match.group('ext') == 'bmp':\n",
    "                image_data = match.groupdict()\n",
    "                image_data['name'] = os.path.splitext(file)[0]\n",
    "                image_data['raw_image_folder'] = root\n",
    "                image_data['file'] = file\n",
    "                image_data['projected_npz'] = \"N\"\n",
    "                image_data['projected_file'] = \"N\"\n",
    "                image_data['idUnique'] = image_data['id'] + image_data['gender']\n",
    "                images_data.append(image_data)\n",
    "    return images_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a669ed9-089d-4fe4-84e1-ca07295dda19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def linearRegression(df, idUnique, emotion, verbose=True):\n",
    "\n",
    "    # 1. Preparar los datos\n",
    "    data = getByUniqueIdEmotion(df, idUnique, emotion)\n",
    "    \n",
    "    # Supongamos que tienes los siguientes datos:\n",
    "    vectores_latentes = [getNPZ(data, index) for index in data.index] # Lista de vectores latentes, cada uno con forma (1, 18, 512)\n",
    "    niveles_emocion = [1, 2, 3, 4]  # Lista de niveles de emocion asociados, cada uno es un escalar\n",
    "    \n",
    "    # Convertir los vectores latentes a una matriz de forma (n_samples, 18 * 512)\n",
    "    X = np.array([vector.reshape(-1) for vector in vectores_latentes])  # Aplana cada vector latente a 1D\n",
    "    y = np.array(niveles_emocion)  # Convertir los niveles de felicidad a un array numpy\n",
    "    \n",
    "    # 2. Ajustar el modelo de regresión lineal\n",
    "    \n",
    "    # Crear el modelo de regresión lineal\n",
    "    modelo = LinearRegression()\n",
    "    \n",
    "    # Ajustar el modelo a los datos\n",
    "    modelo.fit(X, y)\n",
    "    \n",
    "    # Obtener la dirección de emocion en el espacio latente\n",
    "    direccion_emocion = modelo.coef_.reshape(1, 18, 512)\n",
    "\n",
    "    optional_print(f'Executed Linear Regression for person: {idUnique}, emotion: {emotion}.', verbose)\n",
    "    return direccion_emocion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d39c99-6f5d-42ad-96eb-796eff7c3ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "verbosity = True\n",
    "\n",
    "# Define the base directory\n",
    "base_dir = \"/mnt/discoAmpliado/viky/BU_3DFE\"\n",
    "\n",
    "images_data = create_image_dir(base_dir, verbosity)\n",
    "\n",
    "# TODO: Hacer andar el docker que proyecta\n",
    "##align_images(images_data[0:2], verbosity)\n",
    "##df = batch_processing(images_data[0:2], verbosity)\n",
    "# df = load_dataframe()\n",
    "\n",
    "# TODO: A partir de acá sigo como si ya tuviera las imágenes proyectadas, porque sino no llego a ningún lado.\n",
    "df = pd.read_csv(f'/mnt/discoAmpliado/viky/dataframes/processed_dataframe_combined_fallback.csv')\n",
    "df['idUnique'] = df['id'].astype(str) + df['gender']\n",
    "\n",
    "# Crear lista de emociones y eliminar 'NE'\n",
    "emociones = df.exp.unique().tolist()\n",
    "emociones.remove(\"NE\")\n",
    "\n",
    "# Crear lista de IDs y eliminar IDs no deseados\n",
    "ids = df.idUnique.unique().tolist()\n",
    "ids_malos = [\"39M\", \"17M\", \"22M\", \"14M\", \"2F\"] # TODO: Sacar esto cuando pueda arreglar el docker\n",
    "for id_malo in ids_malos:\n",
    "    ids.remove(id_malo)\n",
    "\n",
    "# Crear un DataFrame vacío con IDs como índice y emociones como columnas\n",
    "emociones_total_LR = pd.DataFrame(index=ids, columns=emociones)\n",
    "emociones_total_PCA = pd.DataFrame(index=ids, columns=emociones)\n",
    "\n",
    "# Calcular el vector de cada emoción para cada persona\n",
    "for emocion in emociones:\n",
    "    for idUnique in ids:\n",
    "        # LR\n",
    "        direccion_emocion = linearRegression(df, idUnique, emocion, False)\n",
    "        emociones_total_LR.at[idUnique, emocion] = direccion_emocion.flatten()\n",
    "        \n",
    "        # PCA\n",
    "        ##direccion_emocion = executePCA(df, idUnique, emocion, False)\n",
    "        ##emociones_total_PCA.at[idUnique, emocion] = direccion_emocion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc4499-228b-411e-adb5-31f6a37de913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc()[0]\n",
    "getNPZ(df, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8b02c-9231-4722-96aa-77532df3ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def restar_neutro(df, vectores):\n",
    "    \"\"\"\n",
    "    Resta el vector de expresión neutra a cada imagen de la misma persona.\n",
    "\n",
    "    Parámetros:\n",
    "    - df: DataFrame con información de las imágenes.\n",
    "    - vectores: Diccionario con los vectores de cada imagen. {nombre_imagen: vector}\n",
    "    \n",
    "    Retorna:\n",
    "    - nuevo_diccionario: {nombre_imagen: vector_transformado}\n",
    "    \"\"\"\n",
    "    nuevo_diccionario = {}\n",
    "    \n",
    "    for idUnique in df['idUnique'].unique():\n",
    "        # Obtener el vector neutro de la persona\n",
    "        fila_neutra = df[(df['idUnique'] == idUnique) & (df['exp'] == 'NE')]  # NE sería neutral\n",
    "        if fila_neutra.empty:\n",
    "            continue\n",
    "        vector_neutro = vectores[fila_neutra.iloc[0]['name']]\n",
    "\n",
    "        # Restarlo a las otras expresiones\n",
    "        for _, fila in df[df['idUnique'] == idUnique].iterrows():\n",
    "            nombre_imagen = fila['name']\n",
    "            if nombre_imagen in vectores:\n",
    "                nuevo_diccionario[nombre_imagen] = vectores[nombre_imagen] - vector_neutro\n",
    "\n",
    "    return nuevo_diccionario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae95b8-74a4-4c4f-8a36-03141075190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def obtener_vectores_promediados(df, vectores_neutralizados):\n",
    "    \"\"\"\n",
    "    Promedia los 4 niveles de cada emoción para cada persona.\n",
    "\n",
    "    Parámetros:\n",
    "    - df: DataFrame con información de las imágenes.\n",
    "    - vectores_neutralizados: Diccionario con los vectores restados.\n",
    "\n",
    "    Retorna:\n",
    "    - diccionario_promediado: {idUnique: {emocion: vector_promediado}}\n",
    "    \"\"\"\n",
    "    diccionario_promediado = {}\n",
    "\n",
    "    for idUnique in df['idUnique'].unique():\n",
    "        diccionario_promediado[idUnique] = {}\n",
    "\n",
    "        for emocion in df['exp'].unique():\n",
    "            if emocion == 'NE':  # No considerar la expresión neutra\n",
    "                continue\n",
    "\n",
    "            # Obtener los vectores de los 4 niveles\n",
    "            filas = df[(df['idUnique'] == idUnique) & (df['exp'] == emocion)]\n",
    "            vectores = [vectores_neutralizados[fila['name']] for _, fila in filas.iterrows()]\n",
    "\n",
    "            # Normalizar cada vector y luego promediar\n",
    "            if vectores:\n",
    "                vectores = np.array(vectores)\n",
    "                vectores_normalizados = normalize(vectores, axis=1)  # Normaliza cada vector individualmente\n",
    "                vector_promedio = np.mean(vectores_normalizados, axis=0)\n",
    "\n",
    "                diccionario_promediado[idUnique][emocion] = vector_promedio\n",
    "\n",
    "    return diccionario_promediado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8090531f-2451-4837-ade2-cacf32d91b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def calcular_direccion_emocion(df, vectores_promediados):\n",
    "    \"\"\"\n",
    "    Usa regresión lineal para encontrar la dirección de cada emoción.\n",
    "\n",
    "    Parámetros:\n",
    "    - df: DataFrame con información de las imágenes.\n",
    "    - vectores_promediados: {idUnique: {emocion: vector}}\n",
    "\n",
    "    Retorna:\n",
    "    - direcciones: {emocion: vector_direccion}\n",
    "    \"\"\"\n",
    "    direcciones = {}\n",
    "\n",
    "    for emocion in df['exp'].unique():\n",
    "        if emocion == 'NE':\n",
    "            continue\n",
    "\n",
    "        X = []\n",
    "        for idUnique in vectores_promediados:\n",
    "            if emocion in vectores_promediados[idUnique]:\n",
    "                X.append(vectores_promediados[idUnique][emocion].flatten())  # Asegurarse de que sean arrays 1D\n",
    "\n",
    "        if X:\n",
    "            X = np.array(X)\n",
    "            y = np.ones(len(X))  # No importa realmente el valor de y, porque nos interesa la dirección\n",
    "\n",
    "            modelo = LinearRegression(fit_intercept=False)\n",
    "            modelo.fit(X, y)\n",
    "\n",
    "            direcciones[emocion] = modelo.coef_\n",
    "\n",
    "    return direcciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7180c651-6f5e-452a-aeb3-a2e53f76c4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1525c3-ef8f-4857-93c6-2ffd7adcc2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e00cd9-6271-40f4-8537-66939133a181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15ff9269-bcf9-48e7-8f0d-86e54ed18959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados método 1, 'DI': (1, 18, 512)\n",
      "Resultados método 2, 'DI': (1, 18, 512)\n",
      "Resultados método 3, 'DI': (1, 18, 512)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def load_latent_vector(name):\n",
    "    \"\"\"Carga el vector latente desde un archivo .npz basado en el nombre de la imagen.\"\"\"\n",
    "    path = f'/mnt/discoAmpliado/viky/images/results_BU_3DFE/{name}/projected_w.npz'\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"El archivo {path} no existe.\")\n",
    "    data = np.load(path)\n",
    "    return data['w']  # Suponiendo que la clave dentro del .npz es 'w'\n",
    "\n",
    "def normalize_vectors(vectors):\n",
    "    \"\"\"Normaliza una lista de vectores usando norma L2.\"\"\"\n",
    "    original_shape = vectors.shape  # Guardamos la forma original\n",
    "    vectors = vectors.reshape(vectors.shape[0], -1)  # Aplanamos a (N, D)\n",
    "    vectors = normalize(vectors, axis=1)  # Normalizamos en la dimensión correcta\n",
    "    return vectors.reshape(original_shape)  # Restauramos la forma original\n",
    "\n",
    "def method_1_average_then_regression(df):\n",
    "    \"\"\"Método 1: Promedia los vectores por emoción y aplica regresión.\"\"\"\n",
    "    results = {}\n",
    "    emotions = ['DI', 'HA', 'SU', 'AN', 'SA', 'FE']  # Suponiendo estas emociones\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        subset = df[df['exp'] == emotion]\n",
    "        vectors = np.array([load_latent_vector(name) for name in subset['name']])\n",
    "        vectors = normalize_vectors(vectors)\n",
    "        avg_vector = np.mean(vectors, axis=0)\n",
    "        \n",
    "        X = np.arange(len(vectors)).reshape(-1, 1)\n",
    "        y = vectors.reshape(vectors.shape[0], -1)  # Aplanamos los vectores antes de la regresión\n",
    "\n",
    "        model = LinearRegression().fit(X, y)\n",
    "        results[emotion] = model.coef_.reshape(1, 18, 512)  # Restauramos la forma original\n",
    "    \n",
    "    return results\n",
    "\n",
    "def method_2_regression_by_emotion_and_level(df):\n",
    "    \"\"\"Método 2: Aplica regresión a cada emoción y nivel de intensidad.\"\"\"\n",
    "    results = {}\n",
    "    emotions = ['DI', 'HA', 'SU', 'AN', 'SA', 'FE']\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        results[emotion] = {}  # Ahora almacenamos los resultados por nivel\n",
    "        \n",
    "        for level in sorted(df['exp_level'].unique()):\n",
    "            subset = df[(df['exp'] == emotion) & (df['exp_level'] == level)]\n",
    "            if subset.empty:\n",
    "                continue\n",
    "            vectors = np.array([load_latent_vector(name) for name in subset['name']])\n",
    "            vectors = normalize_vectors(vectors)\n",
    "            \n",
    "            X = np.arange(len(vectors)).reshape(-1, 1)\n",
    "            y = vectors.reshape(vectors.shape[0], -1)  # Aplanamos los vectores antes de la regresión\n",
    "            \n",
    "            model = LinearRegression().fit(X, y)\n",
    "            results[emotion][level] = model.coef_.reshape(1, 18, 512)  # Guardamos cada nivel separadamente\n",
    "    \n",
    "    return results\n",
    "\n",
    "def method_3_regression_with_level_variable(df):\n",
    "    \"\"\"Método 3: Incluye el nivel como variable numérica en la regresión.\"\"\"\n",
    "    results = {}\n",
    "    emotions = ['DI', 'HA', 'SU', 'AN', 'SA', 'FE']\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        subset = df[df['exp'] == emotion]\n",
    "        vectors = np.array([load_latent_vector(name) for name in subset['name']])\n",
    "        vectors = normalize_vectors(vectors)\n",
    "        levels = subset['exp_level'].values.reshape(-1, 1)\n",
    "\n",
    "        y = vectors.reshape(vectors.shape[0], -1)\n",
    "        \n",
    "        model = LinearRegression().fit(levels, y)\n",
    "        results[emotion] = model.coef_.reshape(1, 18, 512)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_results_as_csv(results, filename):\n",
    "    flat_results = {}\n",
    "    \n",
    "    for key, value in results.items():\n",
    "        flat_results[key] = value.flatten()  # Aplanar la matriz\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(flat_results, orient='index')\n",
    "    df.to_csv(filename)\n",
    "\n",
    "    save_results_as_csv(method_1_results, 'method_1_results.csv')\n",
    "\n",
    "\n",
    "def save_results_as_npz(results, filename):\n",
    "    \"\"\"Guarda los resultados en un archivo NPZ.\"\"\"\n",
    "    np.savez(filename, **results)\n",
    "\n",
    "# Cargar datos y ejecutar procesos\n",
    "df = pd.read_csv('/mnt/discoAmpliado/viky/dataframes/processed_dataframe_combined_fallback.csv')  # Ajustar la ruta al dataset\n",
    "df['idUnique'] = df['id'].astype(str) + df['gender']\n",
    "ids_malos = [\"39M\", \"17M\", \"22M\", \"14M\", \"2F\"]\n",
    "df = df[~df['idUnique'].isin(ids_malos)]\n",
    "\n",
    "method_1_results = method_1_average_then_regression(df)\n",
    "method_2_results = method_2_regression_by_emotion_and_level(df)\n",
    "method_3_results = method_3_regression_with_level_variable(df)\n",
    "\n",
    "print(\"Resultados método 1, 'DI': \" + str(method_1_results['DI'].shape))\n",
    "print(\"Resultados método 2, 'DI': \" + str(method_2_results['DI'][1].shape))\n",
    "print(\"Resultados método 3, 'DI': \" + str(method_3_results['DI'].shape))\n",
    "\n",
    "# Guardar resultados\n",
    "##save_results_as_csv(method_1_results, 'method_1_results.csv')\n",
    "save_results_as_npz(method_1_results, 'method_1_results.npz')\n",
    "##save_results_as_csv(method_2_results, 'method_2_results.csv')\n",
    "save_results_as_npz(method_2_results, 'method_2_results.npz')\n",
    "##save_results_as_csv(method_3_results, 'method_3_results.csv')\n",
    "save_results_as_npz(method_3_results, 'method_3_results.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c2e35a8-064f-407b-a835-e39bfe9e37d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del diccionario correspondiente al método 1: \n",
      "Clave: DI ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: HA ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: SU ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: AN ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: SA ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: FE ; Valor: Array de la forma (1, 18, 512)\n",
      "Fin del diccionario correspondiente al método 1.\n",
      "\n",
      "Forma del diccionario correspondiente al método 2: \n",
      "Clave: DI ; Valor: Diccionario con las siguientes claves: \n",
      "  Clave: 1 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 2 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 3 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 4 ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: HA ; Valor: Diccionario con las siguientes claves: \n",
      "  Clave: 1 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 2 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 3 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 4 ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: SU ; Valor: Diccionario con las siguientes claves: \n",
      "  Clave: 1 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 2 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 3 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 4 ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: AN ; Valor: Diccionario con las siguientes claves: \n",
      "  Clave: 1 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 2 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 3 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 4 ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: SA ; Valor: Diccionario con las siguientes claves: \n",
      "  Clave: 1 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 2 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 3 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 4 ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: FE ; Valor: Diccionario con las siguientes claves: \n",
      "  Clave: 1 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 2 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 3 ; Valor: Array de la forma (1, 18, 512)\n",
      "  Clave: 4 ; Valor: Array de la forma (1, 18, 512)\n",
      "Fin del diccionario correspondiente al método 2.\n",
      "\n",
      "Forma del diccionario correspondiente al método 3: \n",
      "Clave: DI ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: HA ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: SU ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: AN ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: SA ; Valor: Array de la forma (1, 18, 512)\n",
      "Clave: FE ; Valor: Array de la forma (1, 18, 512)\n",
      "Fin del diccionario correspondiente al método 3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_shape(diccionario, indent=0):\n",
    "    for clave, valor in diccionario.items():\n",
    "        # Indentación para la estructura\n",
    "        print(\"  \" * indent + f\"Clave: {clave}\", end=' ')\n",
    "        \n",
    "        if isinstance(valor, dict):\n",
    "            # Si el valor es otro diccionario, lo recorremos recursivamente\n",
    "            print(\"; Valor: Diccionario con las siguientes claves: \")\n",
    "            print_shape(valor, indent + 1)\n",
    "        elif isinstance(valor, np.ndarray):\n",
    "            # Si el valor es un array de NumPy, mostramos su forma\n",
    "            print(f\"; Valor: Array de la forma {valor.shape}\")\n",
    "        elif isinstance(valor, list):\n",
    "            # Si el valor es una lista, mostramos su longitud\n",
    "            print(f\"(Lista) - Shape: {len(valor)}\")\n",
    "        else:\n",
    "            # Si no es ni diccionario, ni array ni lista, solo mostramos el tipo\n",
    "            print(f\"({type(valor).__name__})\")\n",
    "\n",
    "print(\"Forma del diccionario correspondiente al método 1: \")\n",
    "print_shape(method_1_results)\n",
    "print(\"Fin del diccionario correspondiente al método 1.\\n\")\n",
    "print(\"Forma del diccionario correspondiente al método 2: \")\n",
    "print_shape(method_2_results)\n",
    "print(\"Fin del diccionario correspondiente al método 2.\\n\")\n",
    "print(\"Forma del diccionario correspondiente al método 3: \")\n",
    "print_shape(method_3_results)\n",
    "print(\"Fin del diccionario correspondiente al método 3.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c6da64-2237-4717-8527-6fadfaa1054f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2dccc73-9e70-4e37-bd65-1fa10ff1e79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>id</th>\n",
       "      <th>exp</th>\n",
       "      <th>exp_level</th>\n",
       "      <th>race</th>\n",
       "      <th>attribute</th>\n",
       "      <th>ext</th>\n",
       "      <th>name</th>\n",
       "      <th>raw_image_folder</th>\n",
       "      <th>file</th>\n",
       "      <th>projected_npz</th>\n",
       "      <th>projected_file</th>\n",
       "      <th>idUnique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>AN</td>\n",
       "      <td>1</td>\n",
       "      <td>WH</td>\n",
       "      <td>F2D</td>\n",
       "      <td>bmp</td>\n",
       "      <td>F0054_AN01WH_F2D</td>\n",
       "      <td>/home/vicky/Documents/BU_3DFE/F0054</td>\n",
       "      <td>F0054_AN01WH_F2D.bmp</td>\n",
       "      <td>[[[ 0.9724985   0.13166972  1.008977   ...  0....</td>\n",
       "      <td>images/results/BU_3DFE/F0054_AN01WH_F2D/projec...</td>\n",
       "      <td>54F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>NE</td>\n",
       "      <td>0</td>\n",
       "      <td>WH</td>\n",
       "      <td>F2D</td>\n",
       "      <td>bmp</td>\n",
       "      <td>F0054_NE00WH_F2D</td>\n",
       "      <td>/home/vicky/Documents/BU_3DFE/F0054</td>\n",
       "      <td>F0054_NE00WH_F2D.bmp</td>\n",
       "      <td>[[[-0.78966004  2.7504096   1.835071   ...  0....</td>\n",
       "      <td>images/results/BU_3DFE/F0054_NE00WH_F2D/projec...</td>\n",
       "      <td>54F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>SU</td>\n",
       "      <td>1</td>\n",
       "      <td>WH</td>\n",
       "      <td>F2D</td>\n",
       "      <td>bmp</td>\n",
       "      <td>F0054_SU01WH_F2D</td>\n",
       "      <td>/home/vicky/Documents/BU_3DFE/F0054</td>\n",
       "      <td>F0054_SU01WH_F2D.bmp</td>\n",
       "      <td>[[[-0.95715564 -0.6468469   0.31578222 ... -0....</td>\n",
       "      <td>images/results/BU_3DFE/F0054_SU01WH_F2D/projec...</td>\n",
       "      <td>54F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>HA</td>\n",
       "      <td>3</td>\n",
       "      <td>WH</td>\n",
       "      <td>F2D</td>\n",
       "      <td>bmp</td>\n",
       "      <td>F0054_HA03WH_F2D</td>\n",
       "      <td>/home/vicky/Documents/BU_3DFE/F0054</td>\n",
       "      <td>F0054_HA03WH_F2D.bmp</td>\n",
       "      <td>[[[ 0.21925983  0.20221505  0.10414152 ...  0....</td>\n",
       "      <td>images/results/BU_3DFE/F0054_HA03WH_F2D/projec...</td>\n",
       "      <td>54F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>FE</td>\n",
       "      <td>4</td>\n",
       "      <td>WH</td>\n",
       "      <td>F2D</td>\n",
       "      <td>bmp</td>\n",
       "      <td>F0054_FE04WH_F2D</td>\n",
       "      <td>/home/vicky/Documents/BU_3DFE/F0054</td>\n",
       "      <td>F0054_FE04WH_F2D.bmp</td>\n",
       "      <td>[[[ 0.08871058 -1.3138419   0.97178036 ...  1....</td>\n",
       "      <td>images/results/BU_3DFE/F0054_FE04WH_F2D/projec...</td>\n",
       "      <td>54F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender  id exp  exp_level race attribute  ext              name  \\\n",
       "124      F  54  AN          1   WH       F2D  bmp  F0054_AN01WH_F2D   \n",
       "125      F  54  NE          0   WH       F2D  bmp  F0054_NE00WH_F2D   \n",
       "126      F  54  SU          1   WH       F2D  bmp  F0054_SU01WH_F2D   \n",
       "127      F  54  HA          3   WH       F2D  bmp  F0054_HA03WH_F2D   \n",
       "128      F  54  FE          4   WH       F2D  bmp  F0054_FE04WH_F2D   \n",
       "\n",
       "                        raw_image_folder                  file  \\\n",
       "124  /home/vicky/Documents/BU_3DFE/F0054  F0054_AN01WH_F2D.bmp   \n",
       "125  /home/vicky/Documents/BU_3DFE/F0054  F0054_NE00WH_F2D.bmp   \n",
       "126  /home/vicky/Documents/BU_3DFE/F0054  F0054_SU01WH_F2D.bmp   \n",
       "127  /home/vicky/Documents/BU_3DFE/F0054  F0054_HA03WH_F2D.bmp   \n",
       "128  /home/vicky/Documents/BU_3DFE/F0054  F0054_FE04WH_F2D.bmp   \n",
       "\n",
       "                                         projected_npz  \\\n",
       "124  [[[ 0.9724985   0.13166972  1.008977   ...  0....   \n",
       "125  [[[-0.78966004  2.7504096   1.835071   ...  0....   \n",
       "126  [[[-0.95715564 -0.6468469   0.31578222 ... -0....   \n",
       "127  [[[ 0.21925983  0.20221505  0.10414152 ...  0....   \n",
       "128  [[[ 0.08871058 -1.3138419   0.97178036 ...  1....   \n",
       "\n",
       "                                        projected_file idUnique  \n",
       "124  images/results/BU_3DFE/F0054_AN01WH_F2D/projec...      54F  \n",
       "125  images/results/BU_3DFE/F0054_NE00WH_F2D/projec...      54F  \n",
       "126  images/results/BU_3DFE/F0054_SU01WH_F2D/projec...      54F  \n",
       "127  images/results/BU_3DFE/F0054_HA03WH_F2D/projec...      54F  \n",
       "128  images/results/BU_3DFE/F0054_FE04WH_F2D/projec...      54F  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308a57b-12e9-436b-9a0c-478f7a6d1354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stylegan)",
   "language": "python",
   "name": "stylegan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
